{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3a64f37",
   "metadata": {},
   "source": [
    "# Evaluaci√≥n de M√©tricas - Proyecto NLP: An√°lisis de Sentimientos\n",
    "\n",
    "**Proyecto:** Procesamiento de Lenguaje Natural - Clasificaci√≥n de Sentimientos  \n",
    "**Corpus:** 2,000+ documentos  \n",
    "**Total de instancias:** 32,518"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8f080e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Evaluaci√≥n del Modelo CNN (Mejor Modelo)\n",
    "\n",
    "### 1.1 Matriz de Confusi√≥n\n",
    "\n",
    "El modelo CNN seleccionado como mejor modelo muestra los siguientes resultados en la matriz de confusi√≥n:\n",
    "\n",
    "|              | **Predicci√≥n 0** | **Predicci√≥n 1** | **Predicci√≥n 2** |\n",
    "|--------------|------------------|------------------|------------------|\n",
    "| **Real 0**   | 6,479            | 275              | 346              |\n",
    "| **Real 1**   | 168              | 10,683           | 131              |\n",
    "| **Real 2**   | 809              | 259              | 13,368           |\n",
    "\n",
    "**Interpretaci√≥n:**\n",
    "- La diagonal principal (6,479 + 10,683 + 13,368 = 30,530) representa las predicciones correctas\n",
    "- Total de instancias: 32,518\n",
    "- Las confusiones m√°s significativas ocurren entre Clase 0 y Clase 2\n",
    "\n",
    "### 1.2 M√©tricas de Desempe√±o\n",
    "\n",
    "**Accuracy Global:**\n",
    "```\n",
    "Accuracy = (6,479 + 10,683 + 13,368) / 32,518 = 30,530 / 32,518 = 0.9389 (93.89%)\n",
    "```\n",
    "\n",
    "**M√©tricas por Clase:**\n",
    "\n",
    "#### Clase 0 (Negativo)\n",
    "- **Total real:** 7,100 instancias\n",
    "- **Correctamente clasificadas:** 6,479\n",
    "- **Precision:** 6,479 / (6,479 + 168 + 809) = 6,479 / 7,456 = 0.869 (86.9%)\n",
    "- **Recall:** 6,479 / 7,100 = 0.913 (91.3%)\n",
    "- **F1-Score:** 2 √ó (0.869 √ó 0.913) / (0.869 + 0.913) = 0.890\n",
    "\n",
    "#### Clase 1 (Neutral)\n",
    "- **Total real:** 10,982 instancias\n",
    "- **Correctamente clasificadas:** 10,683\n",
    "- **Precision:** 10,683 / (275 + 10,683 + 259) = 10,683 / 11,217 = 0.952 (95.2%)\n",
    "- **Recall:** 10,683 / 10,982 = 0.973 (97.3%)\n",
    "- **F1-Score:** 2 √ó (0.952 √ó 0.973) / (0.952 + 0.973) = 0.962\n",
    "\n",
    "#### Clase 2 (Positivo)\n",
    "- **Total real:** 14,436 instancias\n",
    "- **Correctamente clasificadas:** 13,368\n",
    "- **Precision:** 13,368 / (346 + 131 + 13,368) = 13,368 / 13,845 = 0.966 (96.6%)\n",
    "- **Recall:** 13,368 / 14,436 = 0.926 (92.6%)\n",
    "- **F1-Score:** 2 √ó (0.966 √ó 0.926) / (0.966 + 0.926) = 0.945\n",
    "\n",
    "### 1.3 Resumen de M√©tricas CNN\n",
    "\n",
    "| M√©trica         | Clase 0 (Negativo) | Clase 1 (Neutral) | Clase 2 (Positivo) | **Promedio** |\n",
    "|-----------------|--------------------|--------------------|-----------------------|--------------|\n",
    "| **Precision**   | 86.9%              | 95.2%              | 96.6%                 | **92.9%**    |\n",
    "| **Recall**      | 91.3%              | 97.3%              | 92.6%                 | **93.7%**    |\n",
    "| **F1-Score**    | 0.890              | 0.962              | 0.945                 | **0.932**    |\n",
    "| **Soporte**     | 7,100              | 10,982             | 14,436                | 32,518       |\n",
    "\n",
    "**Observaciones:**\n",
    "- La Clase 1 (Neutral) tiene el mejor desempe√±o con F1-Score de 0.962\n",
    "- La Clase 0 (Negativo) muestra mayor confusi√≥n, especialmente con la Clase 2\n",
    "- El modelo tiene excelente desempe√±o general con 93.89% de accuracy\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Modelos Probabil√≠sticos del Lenguaje\n",
    "\n",
    "### 2.1 Comparaci√≥n de Perplejidad\n",
    "\n",
    "Los modelos de n-gramas evaluados muestran los siguientes valores de perplejidad:\n",
    "\n",
    "| Modelo                        | Perplejidad |\n",
    "|-------------------------------|-------------|\n",
    "| Bigram (no smoothing)         | ~0          |\n",
    "| Bigram (Laplace)              | ~10,000     |\n",
    "| Bigram (Add-k, Œ±=0.1)         | ~3,000      |\n",
    "| Trigram (Laplace)             | ~43,000     |\n",
    "\n",
    "**An√°lisis:**\n",
    "- **Bigram (no smoothing):** Perplejidad cercana a 0 indica **sobreajuste** al corpus de entrenamiento\n",
    "- **Bigram (Add-k, Œ±=0.1):** Mejor perplejidad (~3,000), indica buen balance entre ajuste y generalizaci√≥n\n",
    "- **Bigram (Laplace):** Perplejidad moderada (~10,000), buena generalizaci√≥n\n",
    "- **Trigram (Laplace):** Perplejidad muy alta (~43,000) debido a mayor esparcidad en trigramas\n",
    "\n",
    "### 2.2 Comparaci√≥n de Entrop√≠a\n",
    "\n",
    "| Modelo                        | Entrop√≠a (bits) |\n",
    "|-------------------------------|-----------------|\n",
    "| Bigram (no smoothing)         | ~7.0            |\n",
    "| Bigram (Laplace)              | ~13.5           |\n",
    "| Bigram (Add-k, Œ±=0.1)         | ~11.5           |\n",
    "| Trigram (Laplace)             | ~15.5           |\n",
    "\n",
    "**An√°lisis:**\n",
    "- **Menor entrop√≠a:** Bigram (no smoothing) con ~7 bits, pero indica overfitting\n",
    "- **Mejor balance:** Bigram (Add-k) con ~11.5 bits de entrop√≠a\n",
    "- **Mayor incertidumbre:** Trigram (Laplace) con ~15.5 bits, refleja mayor complejidad del modelo\n",
    "\n",
    "**Conclusi√≥n de Modelos Probabil√≠sticos:**\n",
    "El modelo **Bigram con Add-k (Œ±=0.1)** ofrece el mejor compromiso entre perplejidad baja y capacidad de generalizaci√≥n, evitando tanto el overfitting como la alta perplejidad de modelos m√°s complejos.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. An√°lisis de Representaciones de Texto\n",
    "\n",
    "### 3.1 Varianza Explicada por M√©todo\n",
    "\n",
    "Las diferentes t√©cnicas de representaci√≥n vectorial muestran la siguiente varianza explicada en sus primeras componentes principales:\n",
    "\n",
    "| M√©todo          | Varianza Explicada (PC1 + PC2) |\n",
    "|-----------------|--------------------------------|\n",
    "| BoW             | 8.55%                          |\n",
    "| TF-IDF          | 1.17%                          |\n",
    "| PPMI            | 13.01%                         |\n",
    "| Word2Vec        | 16.81%                         |\n",
    "| FastText        | 17.37%                         |\n",
    "\n",
    "**Ranking de Representaciones:**\n",
    "1. ü•á **FastText** - 17.37% (mejor captura de relaciones sem√°nticas)\n",
    "2. ü•à **Word2Vec** - 16.81% (excelente para embeddings densos)\n",
    "3. ü•â **PPMI** - 13.01% (mejor que m√©todos tradicionales)\n",
    "4. **BoW** - 8.55% (representaci√≥n b√°sica)\n",
    "5. **TF-IDF** - 1.17% (menor capacidad de captura de estructura)\n",
    "\n",
    "### 3.2 An√°lisis de Visualizaciones PCA/t-SNE\n",
    "\n",
    "**Observaciones por m√©todo:**\n",
    "\n",
    "#### BoW (Bag of Words)\n",
    "- Varianza explicada: PC1 = 5.6%, PC2 = 2.95%\n",
    "- Muestra patrones de agrupamiento discretos\n",
    "- Separaci√≥n visible entre clases con cierta superposici√≥n\n",
    "\n",
    "#### TF-IDF\n",
    "- Varianza explicada: PC1 = 0.6%, PC2 = 0.57%\n",
    "- Mayor dispersi√≥n de puntos\n",
    "- Estructura menos definida, distribuci√≥n m√°s uniforme\n",
    "- Menor capacidad de captura de relaciones sem√°nticas\n",
    "\n",
    "#### PPMI (Positive Pointwise Mutual Information)\n",
    "- Varianza explicada: PC1 = 11.45%, PC2 = 1.56%\n",
    "- Mejor agrupamiento que BoW y TF-IDF\n",
    "- Captura relaciones de co-ocurrencia significativas\n",
    "- Separaci√≥n m√°s clara entre clases\n",
    "\n",
    "#### Word2Vec\n",
    "- Varianza explicada: PC1 = 10.7%, PC2 = 6.2%\n",
    "- Embeddings densos y bien estructurados\n",
    "- Agrupamiento sem√°ntico claro en el centro\n",
    "- Mejor distribuci√≥n espacial de las clases\n",
    "\n",
    "#### FastText\n",
    "- Varianza explicada: PC1 = 10.3%, PC2 = 7.0%\n",
    "- **Mejor representaci√≥n general**\n",
    "- Agrupamiento muy definido\n",
    "- Captura informaci√≥n de subpalabras\n",
    "- Excelente para manejar palabras fuera de vocabulario\n",
    "\n",
    "### 3.3 Visualizaci√≥n t-SNE de Word2Vec\n",
    "\n",
    "La visualizaci√≥n t-SNE de Word2Vec muestra:\n",
    "- Distribuci√≥n m√°s uniforme de puntos en el espacio 2D\n",
    "- M√∫ltiples clusters distribuidos espacialmente\n",
    "- Separaci√≥n clara entre diferentes grupos sem√°nticos\n",
    "- Estructura rica que indica buena captura de relaciones sem√°nticas\n",
    "\n",
    "**Conclusi√≥n:**\n",
    "**FastText** es la representaci√≥n m√°s efectiva para este corpus, capturando 17.37% de la varianza en las primeras dos componentes, superando a Word2Vec (16.81%) y significativamente a m√©todos tradicionales.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. An√°lisis de T√©rminos Frecuentes por Clase\n",
    "\n",
    "### 4.1 Clase -1 (Sentimiento Negativo)\n",
    "\n",
    "**T√©rminos principales:**\n",
    "- bhonir, onir, poor, time, narendra, know, money\n",
    "- year, now, dont, hate, today, indian, job\n",
    "- govt, country, congress, say, think, wrong, made\n",
    "\n",
    "**Caracter√≠sticas:**\n",
    "- Presencia de t√©rminos cr√≠ticos: \"poor\", \"hate\", \"wrong\", \"dont\"\n",
    "- Vocabulario emocional negativo\n",
    "- Referencias a gobierno y pol√≠tica con connotaci√≥n cr√≠tica\n",
    "\n",
    "### 4.2 Clase 0 (Sentimiento Neutral)\n",
    "\n",
    "**T√©rminos principales:**\n",
    "- now, narendra, opposition, time, ask, know, govt\n",
    "- via, support, year, need, leader, today, modis\n",
    "- indian, work, question, think, made, congress, election\n",
    "\n",
    "**Caracter√≠sticas:**\n",
    "- Vocabulario descriptivo e informativo\n",
    "- T√©rminos de cuestionamiento: \"ask\", \"question\", \"opposition\"\n",
    "- Lenguaje m√°s objetivo y menos emocional\n",
    "- Referencias pol√≠ticas sin juicio de valor expl√≠cito\n",
    "\n",
    "### 4.3 Clase 1 (Sentimiento Positivo)\n",
    "\n",
    "**T√©rminos principales:**\n",
    "- congress, now, narendra, nation, bjp, rahul, govt\n",
    "- india, vote, election, party, people, country, great\n",
    "- good, work, thank, best, modi, sir, leader, support\n",
    "\n",
    "**Caracter√≠sticas:**\n",
    "- T√©rminos de valoraci√≥n positiva: \"great\", \"best\", \"good\", \"thank\"\n",
    "- Expresiones de apoyo: \"support\", \"vote\"\n",
    "- Vocabulario patri√≥tico: \"nation\", \"india\", \"country\"\n",
    "- Tratamiento respetuoso: \"sir\", \"leader\"\n",
    "\n",
    "### 4.4 An√°lisis Transversal\n",
    "\n",
    "**T√©rminos compartidos entre clases:**\n",
    "- \"narendra\", \"modi\", \"congress\", \"govt\", \"country\"\n",
    "- Indica que el corpus trata sobre pol√≠tica india\n",
    "- La diferenciaci√≥n de sentimiento depende del contexto y t√©rminos modificadores\n",
    "\n",
    "**T√©rminos distintivos:**\n",
    "- **Negativo:** hate, poor, wrong, dont\n",
    "- **Neutral:** opposition, question, ask, need\n",
    "- **Positivo:** great, best, thank, support, vote\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Conclusiones Generales\n",
    "\n",
    "### 5.1 Mejor Modelo de Clasificaci√≥n\n",
    "\n",
    "**CNN (Convolutional Neural Network)**\n",
    "- **Accuracy:** 93.89%\n",
    "- **F1-Score promedio:** 0.932\n",
    "- **Mejor clase:** Neutral (F1 = 0.962)\n",
    "- **Clase con m√°s desaf√≠os:** Negativo (F1 = 0.890)\n",
    "\n",
    "**Ventajas del CNN:**\n",
    "- Captura patrones locales en secuencias de texto\n",
    "- Excelente generalizaci√≥n en las tres clases\n",
    "- Supera a modelos tradicionales como Naive Bayes y SVM\n",
    "\n",
    "### 5.2 Mejor Representaci√≥n Vectorial\n",
    "\n",
    "**FastText (17.37% varianza explicada)**\n",
    "- Captura mejor las relaciones sem√°nticas\n",
    "- Maneja eficientemente palabras fuera de vocabulario\n",
    "- Incorpora informaci√≥n de subpalabras\n",
    "- Genera embeddings m√°s robustos\n",
    "\n",
    "### 5.3 Mejor Modelo Probabil√≠stico\n",
    "\n",
    "**Bigram con Add-k smoothing (Œ±=0.1)**\n",
    "- Perplejidad: ~3,000 (mejor balance)\n",
    "- Entrop√≠a: ~11.5 bits\n",
    "- Evita overfitting del no-smoothing\n",
    "- Mejor generalizaci√≥n que Laplace en este corpus\n",
    "\n",
    "### 5.4 Caracter√≠sticas del Corpus\n",
    "\n",
    "**Distribuci√≥n de clases:**\n",
    "- Clase 0 (Negativo): 21.8% (7,100 instancias)\n",
    "- Clase 1 (Neutral): 33.8% (10,982 instancias)\n",
    "- Clase 2 (Positivo): 44.4% (14,436 instancias)\n",
    "\n",
    "**Observaciones:**\n",
    "- Desbalance hacia sentimientos positivos\n",
    "- Corpus enfocado en pol√≠tica india\n",
    "- Vocabulario pol√≠tico dominante en todas las clases\n",
    "\n",
    "### 5.5 Cumplimiento de Objetivos\n",
    "\n",
    "‚úÖ **Preprocesamiento:** Tokenizaci√≥n, stemming, normalizaci√≥n y Levenshtein implementados  \n",
    "‚úÖ **Representaciones:** BoW, TF-IDF, PPMI, Word2Vec y FastText comparados  \n",
    "‚úÖ **Modelos probabil√≠sticos:** N-gramas evaluados con entrop√≠a y perplejidad  \n",
    "‚úÖ **Modelo avanzado:** CNN con 93.89% de accuracy  \n",
    "‚úÖ **Visualizaciones:** PCA y t-SNE para todas las representaciones  \n",
    "\n",
    "---\n",
    "\n",
    "## 6. Recomendaciones\n",
    "\n",
    "### 6.1 Para Mejorar el Modelo\n",
    "\n",
    "1. **Balanceo de clases:** Aplicar t√©cnicas de oversampling/undersampling para equilibrar la distribuci√≥n\n",
    "2. **An√°lisis de errores:** Estudiar las 1,988 instancias mal clasificadas para identificar patrones\n",
    "3. **Ensemble methods:** Combinar CNN con otros modelos para mejorar la robustez\n",
    "4. **Data augmentation:** Generar m√°s ejemplos de la clase negativa\n",
    "\n",
    "### 6.2 Para el Informe Acad√©mico\n",
    "\n",
    "- Incluir la matriz de confusi√≥n como figura principal\n",
    "- Destacar el 93.89% de accuracy del modelo CNN\n",
    "- Comparar con baseline (modelo m√°s simple)\n",
    "- Discutir el impacto del desbalance de clases\n",
    "- Justificar la elecci√≥n de FastText sobre otras representaciones\n",
    "\n",
    "---\n",
    "\n",
    "**Fecha de evaluaci√≥n:** Octubre 2025  \n",
    "**Herramientas utilizadas:** Python, Scikit-learn, TensorFlow/Keras, Matplotlib, Seaborn  \n",
    "**Corpus:** Textos en espa√±ol sobre pol√≠tica indiana (2,000+ documentos)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_proyecto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
